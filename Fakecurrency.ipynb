{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HtTRc7W1dc4GSDgPF6E6Lw2ZpPepovwM",
      "authorship_tag": "ABX9TyMv6M3skE+BP3bnqO3SvTMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sristi222/FakeCurrencyDetector/blob/main/Fakecurrency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kUbin75jW4x7"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Indian Currency Dataset'\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XtqqK3xSXmst"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ],
      "metadata": {
        "id": "iXsYXXgKXtVx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = os.path.join(folder_path, 'train')\n",
        "validation = os.path.join(folder_path, 'validation')\n",
        "test = os.path.join(folder_path, 'test')\n",
        ""
      ],
      "metadata": {
        "id": "KZVmQMjFXy4a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train folders:\", os.listdir(train))\n",
        "print(\"Validation folders:\", os.listdir(validation))\n",
        "print(\"Test folders:\", os.listdir(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI-g4aTYYNr9",
        "outputId": "6816ff0f-d821-42b5-f58c-1550d2c247b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train folders: ['fake', 'real']\n",
            "Validation folders: ['real', 'fake']\n",
            "Test folders: ['fake', 'real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    validation,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_06muCzYTud",
        "outputId": "d2e00fdf-445f-4941-e13f-18a415585ecd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Found 107 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False)\n",
        "base_model.trainable = False  # Freeze the base model\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zox2vmLPYY98",
        "outputId": "ce594eab-3437-4363-d1a7-2bc46cf99ed9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = tf.keras.layers.Flatten()(base_model.output)\n",
        "dropout_layer = tf.keras.layers.Dropout(0.5)(flatten_layer)\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dropout_layer)"
      ],
      "metadata": {
        "id": "z7DUggWXYfGZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Model(base_model.input, output_layer)"
      ],
      "metadata": {
        "id": "akSUOjHtaQlp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "o8IjeVQTaV4q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model.fit(train_generator, epochs=num_epochs, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJK-DuzRaamI",
        "outputId": "8b8e2d6a-529c-4b72-9629-cb5743c5d867"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 10s/step - accuracy: 0.5267 - loss: 2.1177 - val_accuracy: 0.7500 - val_loss: 1.0430\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7225 - loss: 1.3537 - val_accuracy: 0.7333 - val_loss: 0.6260\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.8063 - loss: 0.8528 - val_accuracy: 0.8167 - val_loss: 0.7813\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.7432 - loss: 1.2488 - val_accuracy: 0.7333 - val_loss: 1.0738\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.8025 - loss: 0.8636 - val_accuracy: 0.7667 - val_loss: 0.6814\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.9168 - loss: 0.5487 - val_accuracy: 0.9000 - val_loss: 0.3575\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.8591 - loss: 0.6145 - val_accuracy: 0.8833 - val_loss: 0.3140\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.8977 - loss: 0.3628 - val_accuracy: 0.9167 - val_loss: 0.3973\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.8927 - loss: 0.4376 - val_accuracy: 0.8500 - val_loss: 0.4623\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9186 - loss: 0.2320 - val_accuracy: 0.9500 - val_loss: 0.3555\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7daafc832da0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCP5S512bKlh",
        "outputId": "c285c217-28c2-4bde-bb22-f47e04e9df68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.8358 - loss: 0.5318\n",
            "Test Loss: 0.37314584851264954, Test Accuracy: 0.8785046935081482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Convert RGBA to RGB if needed\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    img = img.resize(target_size)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand dimensions to match the model's input shape (1, 224, 224, 3)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "def predict_currency(image_path, model):\n",
        "    preprocessed_image = load_and_preprocess_image(image_path)\n",
        "    prediction = model.predict(preprocessed_image)\n",
        "    if prediction[0][0] >= 0.5:\n",
        "        return \"Real Nepali Currency\"\n",
        "    else:\n",
        "        return \"Fake Nepali Currency\""
      ],
      "metadata": {
        "id": "ZlevxZZkbP41"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_image_real = '/content/drive/MyDrive/Colab Notebooks/Indian Currency Dataset/validation/real/NEPALI REAL NOTE.png'\n",
        "result = predict_currency(example_image_real, model)\n",
        "print(f\"The predicted result is: {result}\")\n",
        "\n",
        "example_image_fake = '/content/drive/MyDrive/Colab Notebooks/Indian Currency Dataset/validation/fake/1 (1) - Copy.jpg'\n",
        "result = predict_currency(example_image_fake, model)\n",
        "print(f\"The predicted result is: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GR8UE1bbWxb",
        "outputId": "2d5296f7-f591-4873-afb0-fedd61191828"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "The predicted result is: Real Nepali Currency\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "The predicted result is: Fake Nepali Currency\n"
          ]
        }
      ]
    }
  ]
}